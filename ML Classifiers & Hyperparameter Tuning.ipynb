{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>66155.92510</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34415.15397</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>57317.17006</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>42709.53420</td>\n",
       "      <td>45.751972</td>\n",
       "      <td>6103.642260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>66952.68885</td>\n",
       "      <td>18.584336</td>\n",
       "      <td>8770.099235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>59221.04487</td>\n",
       "      <td>48.518179</td>\n",
       "      <td>1926.729397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>69516.12757</td>\n",
       "      <td>23.162104</td>\n",
       "      <td>3503.176156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>44311.44926</td>\n",
       "      <td>28.017167</td>\n",
       "      <td>5522.786693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>43756.05660</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>1622.722598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>69436.57955</td>\n",
       "      <td>56.152617</td>\n",
       "      <td>7378.833599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      clientid       income        age         loan  default\n",
       "0            1  66155.92510  59.017015  8106.532131        0\n",
       "1            2  34415.15397  48.117153  6564.745018        0\n",
       "2            3  57317.17006  63.108049  8020.953296        0\n",
       "3            4  42709.53420  45.751972  6103.642260        0\n",
       "4            5  66952.68885  18.584336  8770.099235        1\n",
       "...        ...          ...        ...          ...      ...\n",
       "1995      1996  59221.04487  48.518179  1926.729397        0\n",
       "1996      1997  69516.12757  23.162104  3503.176156        0\n",
       "1997      1998  44311.44926  28.017167  5522.786693        1\n",
       "1998      1999  43756.05660  63.971796  1622.722598        0\n",
       "1999      2000  69436.57955  56.152617  7378.833599        0\n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Credit Card Default.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data wroangling and cleaning\n",
    "\n",
    "#Removing the 'clientid' column as it's only a unique identifier and doesn't add any value\n",
    "df = df.drop('clientid', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66155.92510</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34415.15397</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57317.17006</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42709.53420</td>\n",
       "      <td>45.751972</td>\n",
       "      <td>6103.642260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66952.68885</td>\n",
       "      <td>18.584336</td>\n",
       "      <td>8770.099235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>59221.04487</td>\n",
       "      <td>48.518179</td>\n",
       "      <td>1926.729397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>69516.12757</td>\n",
       "      <td>23.162104</td>\n",
       "      <td>3503.176156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>44311.44926</td>\n",
       "      <td>28.017167</td>\n",
       "      <td>5522.786693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>43756.05660</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>1622.722598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>69436.57955</td>\n",
       "      <td>56.152617</td>\n",
       "      <td>7378.833599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1997 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           income        age         loan  default\n",
       "0     66155.92510  59.017015  8106.532131        0\n",
       "1     34415.15397  48.117153  6564.745018        0\n",
       "2     57317.17006  63.108049  8020.953296        0\n",
       "3     42709.53420  45.751972  6103.642260        0\n",
       "4     66952.68885  18.584336  8770.099235        1\n",
       "...           ...        ...          ...      ...\n",
       "1995  59221.04487  48.518179  1926.729397        0\n",
       "1996  69516.12757  23.162104  3503.176156        0\n",
       "1997  44311.44926  28.017167  5522.786693        1\n",
       "1998  43756.05660  63.971796  1622.722598        0\n",
       "1999  69436.57955  56.152617  7378.833599        0\n",
       "\n",
       "[1997 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary statistics of the dataset\n",
    "df.describe\n",
    "\n",
    "#Minimum 'age' value is -52, which isn't possible as age cannot be negative <-- Need to clean this up\n",
    "\n",
    "#Checking for all age values <= 0\n",
    "df[df.age <= 0]\n",
    "\n",
    "#There are 3 rows, and we must remove them\n",
    "df = df.drop(df[df.age <= 0].index, axis = 0)\n",
    "df #(Shape = 1997, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66155.92510</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34415.15397</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57317.17006</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42709.53420</td>\n",
       "      <td>45.751972</td>\n",
       "      <td>6103.642260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66952.68885</td>\n",
       "      <td>18.584336</td>\n",
       "      <td>8770.099235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>59221.04487</td>\n",
       "      <td>48.518179</td>\n",
       "      <td>1926.729397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>69516.12757</td>\n",
       "      <td>23.162104</td>\n",
       "      <td>3503.176156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>44311.44926</td>\n",
       "      <td>28.017167</td>\n",
       "      <td>5522.786693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>43756.05660</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>1622.722598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>69436.57955</td>\n",
       "      <td>56.152617</td>\n",
       "      <td>7378.833599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1994 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           income        age         loan  default\n",
       "0     66155.92510  59.017015  8106.532131        0\n",
       "1     34415.15397  48.117153  6564.745018        0\n",
       "2     57317.17006  63.108049  8020.953296        0\n",
       "3     42709.53420  45.751972  6103.642260        0\n",
       "4     66952.68885  18.584336  8770.099235        1\n",
       "...           ...        ...          ...      ...\n",
       "1995  59221.04487  48.518179  1926.729397        0\n",
       "1996  69516.12757  23.162104  3503.176156        0\n",
       "1997  44311.44926  28.017167  5522.786693        1\n",
       "1998  43756.05660  63.971796  1622.722598        0\n",
       "1999  69436.57955  56.152617  7378.833599        0\n",
       "\n",
       "[1994 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for NA value\n",
    "\n",
    "df.isnull().sum()\n",
    "#3 age values are null, and we must remove them\n",
    "\n",
    "#Checking which age values are null\n",
    "df[df.isnull().any(axis = 1)]\n",
    "\n",
    "#Removing these rows\n",
    "df = df.dropna(axis = 0)\n",
    "df #(Shape = 1994, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for duplicates\n",
    "df.duplicated().any() #False\n",
    "#Hence, we can conclude there are no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66155.92510</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34415.15397</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57317.17006</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42709.53420</td>\n",
       "      <td>45.751972</td>\n",
       "      <td>6103.642260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66952.68885</td>\n",
       "      <td>18.584336</td>\n",
       "      <td>8770.099235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>59221.04487</td>\n",
       "      <td>48.518179</td>\n",
       "      <td>1926.729397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>69516.12757</td>\n",
       "      <td>23.162104</td>\n",
       "      <td>3503.176156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>44311.44926</td>\n",
       "      <td>28.017167</td>\n",
       "      <td>5522.786693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>43756.05660</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>1622.722598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>69436.57955</td>\n",
       "      <td>56.152617</td>\n",
       "      <td>7378.833599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1994 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           income        age         loan  default\n",
       "0     66155.92510  59.017015  8106.532131        0\n",
       "1     34415.15397  48.117153  6564.745018        0\n",
       "2     57317.17006  63.108049  8020.953296        0\n",
       "3     42709.53420  45.751972  6103.642260        0\n",
       "4     66952.68885  18.584336  8770.099235        1\n",
       "...           ...        ...          ...      ...\n",
       "1995  59221.04487  48.518179  1926.729397        0\n",
       "1996  69516.12757  23.162104  3503.176156        0\n",
       "1997  44311.44926  28.017167  5522.786693        1\n",
       "1998  43756.05660  63.971796  1622.722598        0\n",
       "1999  69436.57955  56.152617  7378.833599        0\n",
       "\n",
       "[1994 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for non-numeric inputs\n",
    "\n",
    "df.dtypes\n",
    "#Initial impressions show no textual inputs are present, as all columns have integer/float data types\n",
    "\n",
    "for i in df.columns:\n",
    "    df = df[pd.to_numeric(df[i], errors = 'coerce').notnull()]\n",
    "df\n",
    "#df shape = (1994, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66155.92510</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34415.15397</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57317.17006</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42709.53420</td>\n",
       "      <td>45.751972</td>\n",
       "      <td>6103.642260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66952.68885</td>\n",
       "      <td>18.584336</td>\n",
       "      <td>8770.099235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>59221.04487</td>\n",
       "      <td>48.518179</td>\n",
       "      <td>1926.729397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>69516.12757</td>\n",
       "      <td>23.162104</td>\n",
       "      <td>3503.176156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>44311.44926</td>\n",
       "      <td>28.017167</td>\n",
       "      <td>5522.786693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>43756.05660</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>1622.722598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>69436.57955</td>\n",
       "      <td>56.152617</td>\n",
       "      <td>7378.833599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1993 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           income        age         loan  default\n",
       "0     66155.92510  59.017015  8106.532131        0\n",
       "1     34415.15397  48.117153  6564.745018        0\n",
       "2     57317.17006  63.108049  8020.953296        0\n",
       "3     42709.53420  45.751972  6103.642260        0\n",
       "4     66952.68885  18.584336  8770.099235        1\n",
       "...           ...        ...          ...      ...\n",
       "1995  59221.04487  48.518179  1926.729397        0\n",
       "1996  69516.12757  23.162104  3503.176156        0\n",
       "1997  44311.44926  28.017167  5522.786693        1\n",
       "1998  43756.05660  63.971796  1622.722598        0\n",
       "1999  69436.57955  56.152617  7378.833599        0\n",
       "\n",
       "[1993 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Outlier Removal\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "z_scores = stats.zscore(df.astype(np.float))\n",
    "filter = (np.abs(z_scores) < 3).all(axis = 1)\n",
    "df = df[filter]\n",
    "df\n",
    "#df shape = (1994, 3) <-- 1 outlier removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.455269</td>\n",
       "      <td>1.362809</td>\n",
       "      <td>1.206381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.761279</td>\n",
       "      <td>0.541720</td>\n",
       "      <td>0.699293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.838034</td>\n",
       "      <td>1.670987</td>\n",
       "      <td>1.178234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.182059</td>\n",
       "      <td>0.363550</td>\n",
       "      <td>0.547638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.510909</td>\n",
       "      <td>-1.682994</td>\n",
       "      <td>1.424625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.970987</td>\n",
       "      <td>0.571929</td>\n",
       "      <td>-0.826132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1.689921</td>\n",
       "      <td>-1.338149</td>\n",
       "      <td>-0.307645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-0.070193</td>\n",
       "      <td>-0.972417</td>\n",
       "      <td>0.356597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-0.108977</td>\n",
       "      <td>1.736053</td>\n",
       "      <td>-0.926119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1.684366</td>\n",
       "      <td>1.147033</td>\n",
       "      <td>0.967043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1993 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        income       age      loan\n",
       "0     1.455269  1.362809  1.206381\n",
       "1    -0.761279  0.541720  0.699293\n",
       "2     0.838034  1.670987  1.178234\n",
       "3    -0.182059  0.363550  0.547638\n",
       "4     1.510909 -1.682994  1.424625\n",
       "...        ...       ...       ...\n",
       "1995  0.970987  0.571929 -0.826132\n",
       "1996  1.689921 -1.338149 -0.307645\n",
       "1997 -0.070193 -0.972417  0.356597\n",
       "1998 -0.108977  1.736053 -0.926119\n",
       "1999  1.684366  1.147033  0.967043\n",
       "\n",
       "[1993 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalisation\n",
    "\n",
    "from statistics import stdev\n",
    "\n",
    "X = df.iloc[:, 0:-1]\n",
    "Y = df.iloc[:, -1]\n",
    "\n",
    "for i in X.columns:\n",
    "    X[i] = (X[i] - X[i].mean())/stdev(X[i])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical Inputs\n",
    "\n",
    "#As the dataset does not contain any categorical inputs other than the target varaible, we do not need to get dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1710\n",
       "1     283\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for potential class imbalance\n",
    "\n",
    "df['default'].value_counts()\n",
    "#Hence, there is a class imbalance, and we will need to use SMOTE to balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "0    1710\n",
      "1     283\n",
      "Name: default, dtype: int64\n",
      "\n",
      "After\n",
      "1    1710\n",
      "0    1710\n",
      "Name: default, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Fixing the class imbalance\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "oversample = SMOTE()\n",
    "X, Y = oversample.fit_resample(X, Y)\n",
    "\n",
    "#Comparing the before-and-after results\n",
    "print(f\"\"\"Original\n",
    "{df['default'].value_counts()}\"\"\")\n",
    "print()\n",
    "print(f\"\"\"After\n",
    "{Y.value_counts()}\"\"\")\n",
    "\n",
    "#Hence, the class imbalance has been taken care of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split for modelling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9541910331384016"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#===================================================LOGISTIC REGRESSION=========================================================\n",
    "\n",
    "#Model Assumptions:\n",
    "#1. The observations are independent of each other\n",
    "#2. There should be little or no multicollinearity, i.e. the independent variables should not be highly correlated\n",
    "#3. The independent variables should be linearly related to the log odds\n",
    "\n",
    "#Running a basic logistic regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Creating and fitting the model\n",
    "log_reg_model = linear_model.LogisticRegression()\n",
    "log_reg_model.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluating model performance - Trainset\n",
    "log_reg_pred_train = log_reg_model.predict(X_train)\n",
    "log_reg_cm_train = confusion_matrix(log_reg_pred_train, Y_train)\n",
    "log_reg_cm_train\n",
    "\n",
    "#Model accuracy - Trainset\n",
    "log_reg_accuracy_train = (log_reg_cm_train[0, 0] + log_reg_cm_train[1, 1])/sum(sum(log_reg_cm_train))\n",
    "log_reg_accuracy_train\n",
    "#93.98%\n",
    "\n",
    "#Evaluating model performance - Testset\n",
    "log_reg_pred_test = log_reg_model.predict(X_test)\n",
    "log_reg_cm_test = confusion_matrix(log_reg_pred_test, Y_test)\n",
    "log_reg_cm_test\n",
    "\n",
    "#Model accuracy - Testset\n",
    "log_reg_accuracy_test = (log_reg_cm_test[0, 0] + log_reg_cm_test[1, 1])/sum(sum(log_reg_cm_test))\n",
    "log_reg_accuracy_test #0.9541910331384016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x286f6758548>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ns_probs = [0 for _ in range(len(Y_test))]\n",
    "ns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\n",
    "\n",
    "log_reg_probs = log_reg_model.predict_proba(X_test)\n",
    "log_reg_probs = log_reg_probs[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, log_reg_probs)\n",
    "plt.plot(fpr, tpr, marker = '.', label = 'Logistic Regression Model')\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9392460317460318\n",
      "Best Hyperparameters: {'C': 0.11860397910260653, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Time elapsed: 0:00:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py:925: UserWarning: One or more of the test scores are non-finite: [0.93414021        nan 0.93414021        nan 0.89656085 0.90399471\n",
      " 0.82791005 0.50904762        nan        nan        nan        nan\n",
      " 0.93414021        nan 0.93691799        nan        nan 0.93414021\n",
      " 0.50904762        nan 0.93506614 0.7830291  0.93414021 0.50904762\n",
      " 0.93506614        nan 0.93414021        nan 0.93414021 0.93367725\n",
      " 0.59112434        nan 0.93414021        nan 0.93414021 0.93599206\n",
      "        nan 0.93414021 0.50904762        nan 0.92624339 0.93275132\n",
      " 0.50904762 0.8942328         nan 0.64907407        nan        nan\n",
      "        nan        nan        nan 0.93414021        nan 0.93414021\n",
      "        nan 0.93414021        nan        nan        nan        nan\n",
      " 0.93414021        nan 0.93228836 0.90724868        nan 0.82890212\n",
      "        nan 0.93691799 0.93414021 0.50904762        nan        nan\n",
      "        nan        nan 0.93414021 0.93321429        nan 0.87664021\n",
      " 0.78350529 0.93414021        nan 0.93367725 0.50904762        nan\n",
      " 0.50904762        nan 0.93414021 0.8914418         nan        nan\n",
      " 0.79507937        nan        nan 0.93691799        nan        nan\n",
      "        nan        nan 0.78535714        nan        nan        nan\n",
      "        nan 0.89005291 0.93924603        nan 0.93320106        nan\n",
      " 0.78257937 0.90771164        nan        nan 0.9392328         nan\n",
      " 0.93414021 0.93414021 0.93414021        nan        nan 0.93414021\n",
      " 0.93460317 0.93228836 0.93414021        nan 0.78257937 0.54940476\n",
      "        nan        nan 0.88958995        nan 0.50904762 0.93645503\n",
      " 0.93506614 0.78257937 0.78257937 0.93414021        nan 0.93414021\n",
      " 0.93460317        nan 0.91003968        nan 0.93506614        nan\n",
      " 0.85203704 0.93414021 0.93414021 0.93414021 0.66854497        nan\n",
      " 0.93414021 0.78998677 0.66529101 0.93414021        nan        nan\n",
      "        nan        nan 0.9355291  0.50904762 0.93275132        nan\n",
      "        nan        nan        nan 0.92903439        nan        nan\n",
      " 0.93414021 0.93506614 0.93320106        nan        nan 0.93367725\n",
      " 0.89236772        nan        nan 0.82791005        nan 0.93414021\n",
      " 0.93367725        nan 0.50904762        nan 0.93414021 0.50904762\n",
      " 0.93460317        nan        nan        nan 0.93414021 0.89838624\n",
      " 0.93460317 0.93830688 0.93414021 0.89051587        nan        nan\n",
      " 0.93414021        nan        nan 0.50904762 0.93414021 0.50904762\n",
      "        nan        nan        nan 0.93228836 0.93645503 0.93506614\n",
      "        nan 0.93645503 0.93414021        nan        nan 0.93414021\n",
      " 0.83167989        nan        nan        nan 0.50904762        nan\n",
      " 0.93414021        nan        nan        nan 0.89376984 0.93414021\n",
      " 0.93691799        nan 0.50904762 0.78259259        nan        nan\n",
      " 0.85161376 0.50904762 0.93414021 0.93414021        nan        nan\n",
      "        nan 0.93784392 0.93414021        nan 0.93460317        nan\n",
      " 0.93321429 0.50904762        nan        nan        nan 0.93414021\n",
      " 0.91929894        nan        nan 0.50904762        nan 0.78026455\n",
      "        nan 0.93414021        nan 0.50904762 0.78350529 0.93830688\n",
      " 0.93460317        nan 0.92904762 0.50904762        nan 0.90771164\n",
      " 0.93414021        nan 0.68937831        nan        nan 0.93414021\n",
      "        nan        nan 0.92903439 0.92115079 0.93784392        nan\n",
      " 0.93414021        nan 0.93414021 0.93321429        nan 0.8409127\n",
      "        nan        nan 0.50904762 0.50904762        nan        nan\n",
      "        nan 0.93414021        nan 0.92810847 0.89005291        nan\n",
      "        nan 0.93738095        nan        nan        nan 0.50904762\n",
      " 0.93414021        nan 0.93367725 0.93414021        nan 0.50904762\n",
      "        nan 0.93088624        nan 0.93228836 0.93414021 0.93691799\n",
      "        nan        nan 0.93691799 0.93414021        nan 0.8914418\n",
      "        nan 0.93137566 0.50904762 0.93414021 0.93275132 0.91280423\n",
      "        nan 0.53041005        nan 0.93414021 0.93414021 0.93414021\n",
      " 0.93414021 0.93275132 0.93414021        nan        nan 0.50904762\n",
      " 0.93460317        nan        nan        nan 0.93228836        nan\n",
      " 0.93830688        nan        nan        nan 0.56007937 0.65138889\n",
      " 0.93414021 0.93228836        nan 0.7505291  0.72183862 0.93599206\n",
      "        nan        nan 0.50904762 0.89656085 0.93414021 0.78257937\n",
      "        nan 0.92810847 0.81686508 0.93414021        nan 0.91280423\n",
      " 0.93414021 0.78719577 0.9327381         nan 0.93691799        nan\n",
      "        nan        nan        nan        nan        nan 0.90727513\n",
      "        nan 0.7867328         nan        nan 0.93414021        nan\n",
      "        nan        nan        nan 0.93460317        nan 0.93414021\n",
      " 0.93599206 0.89650794 0.93414021        nan        nan 0.93414021\n",
      " 0.50904762 0.50904762 0.93275132 0.78015873        nan        nan\n",
      " 0.50904762 0.50904762 0.55488095        nan        nan        nan\n",
      "        nan 0.50904762 0.9355291         nan 0.50904762 0.78720899\n",
      "        nan        nan 0.93691799        nan 0.50904762        nan\n",
      "        nan 0.91513228        nan        nan        nan        nan\n",
      " 0.50904762        nan        nan        nan        nan        nan\n",
      "        nan 0.93414021 0.78350529 0.89096561        nan 0.93414021\n",
      " 0.50904762 0.93414021        nan 0.93414021 0.89511905        nan\n",
      "        nan 0.93414021 0.85851852        nan        nan 0.89839947\n",
      "        nan        nan 0.93460317        nan 0.93414021        nan\n",
      "        nan 0.93414021        nan        nan        nan 0.93367725\n",
      " 0.93414021 0.93414021        nan        nan        nan        nan\n",
      "        nan 0.91698413 0.90308201        nan 0.89236772        nan\n",
      " 0.93414021        nan        nan 0.93228836        nan        nan\n",
      "        nan        nan 0.93645503        nan 0.93414021 0.93414021\n",
      " 0.90865079        nan 0.86876984        nan 0.93228836        nan\n",
      " 0.93414021        nan]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "#Optimisation of the hyperparameters for our logistic regression model\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from scipy.stats import loguniform\n",
    "from datetime import datetime\n",
    "\n",
    "#Creating a validation set to see the results of hyperparameter tuning\n",
    "X_train1, X_validate, Y_train1, Y_validate = train_test_split(X_train, Y_train, test_size = 0.3)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits = 20, n_repeats = 3, random_state = 1)\n",
    "\n",
    "#Defining the search space\n",
    "search_grid_log_reg = dict()\n",
    "search_grid_log_reg['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "search_grid_log_reg['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "search_grid_log_reg['C'] = loguniform(1e-5, 100)\n",
    "\n",
    "#Defining the search\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "search = RandomizedSearchCV(log_reg_model, search_grid_log_reg, n_iter = 500, scoring = 'accuracy', n_jobs = -1, cv = cv, random_state = 1)\n",
    "result = search.fit(X_validate, Y_validate)\n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_) #{'C': 0.11860397910260653, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
    "\n",
    "format = \"%H:%M:%S\"\n",
    "time_elapsed = datetime.strptime(end_time, format) - datetime.strptime(start_time, format)\n",
    "print(f\"Time elapsed: {time_elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset accuracy before tuning: 0.9541910331384016\n",
      "Testset accuracy after tuning: 0.9551656920077972\n"
     ]
    }
   ],
   "source": [
    "#Using the tuned hyperparameters to re-train the model with the optimised parameters and compare testset accuracy\n",
    "log_reg_model_tuned = linear_model.LogisticRegression(C = 0.11860397910260653, penalty = 'l2', solver = 'newton-cg')\n",
    "log_reg_model_tuned.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluating Model Performance\n",
    "log_reg_tuned_pred_test = log_reg_model_tuned.predict(X_test)\n",
    "log_reg_tuned_cm = confusion_matrix(log_reg_tuned_pred_test, Y_test)\n",
    "log_reg_tuned_accuracy_test = (log_reg_tuned_cm[0, 0] + log_reg_tuned_cm[1, 1])/sum(sum(log_reg_tuned_cm))\n",
    "print(f\"Testset accuracy before tuning: {log_reg_accuracy_test}\") #0.9454191033138402\n",
    "print(f\"Testset accuracy after tuning: {log_reg_tuned_accuracy_test}\") #0.9551656920077972\n",
    "\n",
    "#This is the final, tuned logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset accuracy of the base decision tree model: 1.0\n"
     ]
    }
   ],
   "source": [
    "#======================================================DECISION TREE============================================================\n",
    "\n",
    "#Assumptions:\n",
    "#1. In the beginning, the entire training data is considered as the root\n",
    "#2. The records are distributed recursively on the basis of the attribute value.\n",
    "\n",
    "#Running a decision tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dec_tree_model = DecisionTreeClassifier()\n",
    "dec_tree_model.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluating model performance - Trainset\n",
    "dec_tree_pred_train = dec_tree_model.predict(X_train)\n",
    "dec_tree_cm_train = confusion_matrix(dec_tree_pred_train, Y_train)\n",
    "dec_tree_accuracy_train = (dec_tree_cm_train[0, 0] + dec_tree_cm_train[1, 1])/sum(sum(dec_tree_cm_train))\n",
    "print(f\"Trainset accuracy of the base decision tree model: {dec_tree_accuracy_train}\") #Overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset accuracy of the base decision tree model: 0.9782790309106099\n",
      "Testset accuracy of the base decision tree model: 0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "#Limiting maximum tree depth\n",
    "dec_tree_model.get_depth() #10 - No wonder it overfitted by a lot\n",
    "\n",
    "#Setting the max_depth to 5 to prevent overfitting - Will tune this later\n",
    "dec_tree_model = DecisionTreeClassifier(max_depth = 5)\n",
    "dec_tree_model.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluating model performance - Trainset\n",
    "dec_tree_pred_train = dec_tree_model.predict(X_train)\n",
    "dec_tree_cm_train = confusion_matrix(dec_tree_pred_train, Y_train)\n",
    "dec_tree_accuracy_train = (dec_tree_cm_train[0, 0] + dec_tree_cm_train[1, 1])/sum(sum(dec_tree_cm_train))\n",
    "print(f\"Trainset accuracy of the base decision tree model: {dec_tree_accuracy_train}\") #98.57%\n",
    "\n",
    "#Evaluating model performance - Testset\n",
    "dec_tree_pred_test = dec_tree_model.predict(X_test)\n",
    "dec_tree_cm_test = confusion_matrix(dec_tree_pred_test, Y_test)\n",
    "dec_tree_accuracy_test = (dec_tree_cm_test[0, 0] + dec_tree_cm_test[1, 1])/sum(sum(dec_tree_cm_test))\n",
    "print(f\"Testset accuracy of the base decision tree model: {dec_tree_accuracy_test}\") #97.46%\n",
    "\n",
    "#Seems to be reasonable, given that the logistic regression model obtained an accuracy of 94.73%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9359523809523809\n",
      "Best Hyperparameters: {'ccp_alpha': 0.01926059437058802, 'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt'}\n",
      "Time elapsed: 0:01:11\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimisation for the decision tree model\n",
    "\n",
    "#No need to split into the validation sets again - We can use the ones splitted previously\n",
    "cv = RepeatedStratifiedKFold(n_splits = 20, n_repeats = 3, random_state = 1)\n",
    "\n",
    "#Defining the search space\n",
    "search_grid_dec_tree = dict()\n",
    "search_grid_dec_tree['criterion'] = ['gini', 'entropy']\n",
    "#search_grid_dec_tree['min_samples_split'] = np.arange(start = 19, stop = 30, step = 1) #Chose not to optimise min_samples_split as the result would overlap with max_depth\n",
    "search_grid_dec_tree['max_depth'] = [3, 4, 5] \n",
    "search_grid_dec_tree['max_features'] = ['auto', 'sqrt', 'log2']\n",
    "search_grid_dec_tree['ccp_alpha'] = loguniform(1e-5, 100)\n",
    "\n",
    "#Defining the search\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "search = RandomizedSearchCV(dec_tree_model, search_grid_dec_tree, n_iter = 500, scoring = 'accuracy', n_jobs = -1, cv = cv, random_state = 1)\n",
    "result = search.fit(X_validate, Y_validate)\n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "print('Best Score: %s' % result.best_score_) \n",
    "print('Best Hyperparameters: %s' % result.best_params_) \n",
    "\n",
    "format = \"%H:%M:%S\"\n",
    "time_elapsed = datetime.strptime(end_time, format) - datetime.strptime(start_time, format)\n",
    "print(f\"Time elapsed: {time_elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset accuracy before tuning: 0.9766081871345029\n",
      "Testset accuracy after tuning: 0.9853801169590644\n"
     ]
    }
   ],
   "source": [
    "#Using the tuned hyperparameters to re-train the model with the optimised parameters and compare testset accuracy\n",
    "dec_tree_model_tuned = DecisionTreeClassifier(ccp_alpha = 0.003900131433342812, criterion = 'gini', max_depth = 5, max_features = 'auto')\n",
    "dec_tree_model_tuned.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluating Model Performance\n",
    "dec_tree_tuned_pred_test = dec_tree_model_tuned.predict(X_test)\n",
    "dec_tree_tuned_cm = confusion_matrix(dec_tree_tuned_pred_test, Y_test)\n",
    "dec_tree_tuned_accuracy_test = (dec_tree_tuned_cm[0, 0] + dec_tree_tuned_cm[1, 1])/sum(sum(dec_tree_tuned_cm))\n",
    "print(f\"Testset accuracy before tuning: {dec_tree_accuracy_test}\") #0.9766081871345029\n",
    "print(f\"Testset accuracy after tuning: {dec_tree_tuned_accuracy_test}\") #0.9853801169590644\n",
    "\n",
    "#This is the decision tree model after tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970760233918129"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#==================================================RANDOM FOREST================================================================\n",
    "\n",
    "#No formal assumptions\n",
    "\n",
    "#Running a base random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluating model performance - Trainset\n",
    "rf_model_pred_train = rf_model.predict(X_train)\n",
    "rf_model_cm_train = confusion_matrix(rf_model_pred_train, Y_train)\n",
    "rf_model_accuracy_train = (rf_model_cm_train[0, 0] + rf_model_cm_train[1, 1])/sum(sum(rf_model_cm_train))\n",
    "rf_model_accuracy_train #100%\n",
    "\n",
    "#Evaluating model performance - Testset\n",
    "rf_model_pred_test = rf_model.predict(X_test)\n",
    "rf_model_cm_test = confusion_matrix(rf_model_pred_test, Y_test)\n",
    "rf_model_accuracy_test = (rf_model_cm_test[0, 0] + rf_model_cm_test[1, 1])/sum(sum(rf_model_cm_test))\n",
    "rf_model_accuracy_test #0.9970760233918129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning for Random Forest model\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits = 20, n_repeats = 3, random_state = 1)\n",
    "\n",
    "#Defining the search space\n",
    "search_grid_rf = dict()\n",
    "search_grid_rf['max_features'] = [1, 2, 3]\n",
    "search_grid_rf['n_estimators'] = np.arange(start = 100, stop = 800, step = 50)\n",
    "search_grid_rf['ccp_alpha'] = loguniform(1e-5, 100)\n",
    "\n",
    "#Defining the search\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "search = RandomizedSearchCV(rf_model, search_grid_rf, n_iter = 500, scoring = 'accuracy', n_jobs = -1, cv = cv, random_state = 1)\n",
    "result = search.fit(X_validate, Y_validate)\n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_) #{'ccp_alpha': 4.6711245817425396e-05, 'max_features': 1, 'n_estimators': 450}\n",
    "\n",
    "format = \"%H:%M:%S\"\n",
    "time_elapsed = datetime.strptime(end_time, format) - datetime.strptime(start_time, format)\n",
    "print(f\"Time elapsed: {time_elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset accuracy before tuning: 0.9970760233918129\n",
      "Testset accuracy after tuning: 0.9980506822612085\n"
     ]
    }
   ],
   "source": [
    "#Using the tuned hyperparameters to re-train the model with the optimised parameters and compare testset accuracy\n",
    "\n",
    "rf_model_tuned = RandomForestClassifier(ccp_alpha = 4.6711245817425396e-05, max_features = 1, n_estimators = 450)\n",
    "rf_model_tuned.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluating the tuned model on the testset\n",
    "rf_model_tuned_pred_test = rf_model_tuned.predict(X_test)\n",
    "rf_model_tuned_cm_test = confusion_matrix(rf_model_tuned_pred_test, Y_test)\n",
    "rf_model_tuned_accuracy_test = (rf_model_tuned_cm_test[0, 0] + rf_model_tuned_cm_test[1, 1])/sum(sum(rf_model_tuned_cm_test))\n",
    "    \n",
    "print(f\"Testset accuracy before tuning: {rf_model_accuracy_test}\") #0.9970760233918129\n",
    "print(f\"Testset accuracy after tuning: {rf_model_tuned_accuracy_test}\") #0.9980506822612085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in accuracy (Trainset - Testset): 0.001670843776106934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9970760233918129"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=======================================================XG BOOST================================================================\n",
    "\n",
    "#Assumptions\n",
    "#1. It may have an assumption that encoded integer value for each variable has an ordinal relation\n",
    "\n",
    "#Running a base XG-Boost model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "xgb_model = GradientBoostingClassifier()\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluating model performance - Trainset\n",
    "xgb_model_pred_train = xgb_model.predict(X_train)\n",
    "xgb_model_cm_train = confusion_matrix(xgb_model_pred_train, Y_train)\n",
    "xgb_model_accuracy_train = (xgb_model_cm_train[0, 0] + xgb_model_cm_train[1, 1])/sum(sum(xgb_model_cm_train)) #100% <-- Overfitted\n",
    "\n",
    "#Evaluating model performance - Testset\n",
    "xgb_model_pred_test = xgb_model.predict(X_test)\n",
    "xgb_model_cm_test = confusion_matrix(xgb_model_pred_test, Y_test)\n",
    "xgb_model_accuracy_test = (xgb_model_cm_test[0, 0] + xgb_model_cm_test[1, 1])/sum(sum(xgb_model_cm_test))\n",
    "\n",
    "print(f\"Difference in accuracy (Trainset - Testset): {xgb_model_accuracy_train - xgb_model_accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in accuracy (Trainset - Testset) after limiting max dept: -0.001113895850737956\n",
      "Although the difference is extremely small, the 2nd model (By limiting max_dept to 2) generalises better to unseen data, as shown by the above calculation\n",
      "Hence, will be proceeding to optimise the second model\n"
     ]
    }
   ],
   "source": [
    "#Limiting max_depth to prevent overfitting\n",
    "\n",
    "xgb_model = GradientBoostingClassifier(max_depth = 2)\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluating model performance - Trainset\n",
    "xgb_model_pred_train = xgb_model.predict(X_train)\n",
    "xgb_model_cm_train = confusion_matrix(xgb_model_pred_train, Y_train)\n",
    "xgb_model_accuracy_train = (xgb_model_cm_train[0, 0] + xgb_model_cm_train[1, 1])/sum(sum(xgb_model_cm_train))\n",
    "xgb_model_accuracy_train\n",
    "\n",
    "#Evaluating model performance - Testset\n",
    "xgb_model_pred_test = xgb_model.predict(X_test)\n",
    "xgb_model_cm_test = confusion_matrix(xgb_model_pred_test, Y_test)\n",
    "xgb_model_accuracy_test = (xgb_model_cm_test[0, 0] + xgb_model_cm_test[1, 1])/sum(sum(xgb_model_cm_test))\n",
    "\n",
    "print(f\"Difference in accuracy (Trainset - Testset) after limiting max dept: {xgb_model_accuracy_train - xgb_model_accuracy_test}\")\n",
    "print(\"Although the difference is extremely small, the 2nd model (By limiting max_dept to 2) generalises better to unseen data, as shown by the above calculation\")\n",
    "print(\"Hence, will be proceeding to optimise the second model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py:289: UserWarning: The total space of parameters 252 is smaller than n_iter=500. Running 252 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9847222222222223\n",
      "Best Hyperparameters: {'subsample': 1.0, 'n_estimators': 750, 'max_depth': 2, 'learning_rate': 0.1}\n",
      "Time elapsed: 0:21:35\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning for XGBoost model\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits = 20, n_repeats = 3, random_state = 1)\n",
    "\n",
    "#Defining the search space\n",
    "search_grid_xgb = dict()\n",
    "search_grid_xgb['learning_rate'] = [0.001, 0.01, 0.1]\n",
    "search_grid_xgb['n_estimators'] = np.arange(start = 100, stop = 800, step = 50)\n",
    "search_grid_xgb['subsample'] = [0.5, 0.7, 1.0]\n",
    "search_grid_xgb['max_depth'] = [1, 2] #Not included 3 as 3 gives 100% trainset accuracy\n",
    "\n",
    "#Defining the search\n",
    "start_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "search = RandomizedSearchCV(xgb_model, search_grid_xgb, n_iter = 500, scoring = 'accuracy', n_jobs = -1, cv = cv, random_state = 1)\n",
    "result = search.fit(X_validate, Y_validate)\n",
    "end_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_) #{'subsample': 1.0, 'n_estimators': 750, 'max_depth': 2, 'learning_rate': 0.1}\n",
    "\n",
    "format = \"%H:%M:%S\"\n",
    "time_elapsed = datetime.strptime(end_time, format) - datetime.strptime(start_time, format)\n",
    "print(f\"Time elapsed: {time_elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset accuracy before tuning: 0.99317738791423\n",
      "Testset accuracy after tuning: 0.9941520467836257\n"
     ]
    }
   ],
   "source": [
    "#Using the tuned hyperparameters to re-train the XGBoost model with the optimised parameters and compare testset accuracy\n",
    "\n",
    "xgb_model_tuned = GradientBoostingClassifier(subsample = 1.0, n_estimators = 750, max_depth = 2, learning_rate = 0.1)\n",
    "xgb_model_tuned.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluating the tuned model on the testset\n",
    "xgb_model_tuned_pred_test = xgb_model_tuned.predict(X_test)\n",
    "xgb_model_tuned_cm_test = confusion_matrix(xgb_model_tuned_pred_test, Y_test)\n",
    "xgb_model_tuned_accuracy_test = (xgb_model_tuned_cm_test[0, 0] + xgb_model_tuned_cm_test[1, 1])/sum(sum(xgb_model_tuned_cm_test))\n",
    "    \n",
    "print(f\"Testset accuracy before tuning: {xgb_model_accuracy_test}\") #0.99317738791423\n",
    "print(f\"Testset accuracy after tuning: {xgb_model_tuned_accuracy_test}\") #0.9941520467836257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x286ff22bc88>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#===================================================NEURAL NETWORK==============================================================\n",
    "\n",
    "#Assumptions\n",
    "#1. Neurons are arranged in sequentially arranged layers\n",
    "#2. Neurons within the same layer do not interact with/communicate to each other\n",
    "#3. All inputs enter the network through the input layer and pass through the output layer\n",
    "#4. All hidden layers at the same level have the same activation function\n",
    "#5. Neurons in consecutive layers are densely connected\n",
    "#6. Every inter-connected neural network has it’s own weight and biased associated with it\n",
    "\n",
    "#Running a base neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(10, input_dim = 3, activation = 'relu'))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(10, activation = 'relu'))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "nn_model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics = 'accuracy')\n",
    "\n",
    "nn_model.fit(X_train, Y_train, epochs = 100, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 667us/step - loss: 0.0075 - accuracy: 0.9983\n",
      "33/33 [==============================] - 0s 716us/step - loss: 0.0079 - accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9990253411306043"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating model performance - Trainset\n",
    "#Evaluation\n",
    "nn_evaluation_accuracy_train = nn_model.evaluate(X_train, Y_train) #0.9983291625976562\n",
    "\n",
    "#Prediction\n",
    "nn_model_pred_train = nn_model.predict(X_train)\n",
    "nn_model_pred_train = np.where(nn_model_pred_train>0.5, 1, 0)\n",
    "nn_model_cm_train = confusion_matrix(nn_model_pred_train, Y_train)\n",
    "nn_model_accuracy_train = (nn_model_cm_train[0, 0] + nn_model_cm_train[1, 1])/sum(sum(nn_model_cm_train)) #0.9983291562238931 \n",
    "\n",
    "#Evaluating model performance - Testset\n",
    "#Evaluation\n",
    "nn_evaluation_accuracy_test = nn_model.evaluate(X_test, Y_test) #0.9990253448486328\n",
    "\n",
    "#Prediction\n",
    "nn_model_pred_test = nn_model.predict(X_test)\n",
    "nn_model_pred_test = np.where(nn_model_pred_test>0.5, 1, 0)\n",
    "nn_model_cm_test = confusion_matrix(nn_model_pred_test, Y_test)\n",
    "nn_model_accuracy_test = (nn_model_cm_test[0, 0] + nn_model_cm_test[1, 1])/sum(sum(nn_model_cm_test)) #0.9990253411306043"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
